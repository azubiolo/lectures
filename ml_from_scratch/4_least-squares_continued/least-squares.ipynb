{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Ordinary Least Squares\n",
    "## Course recap\n",
    "This lab consists in implementing the **Ordinary Least Squares** (OLS) algorithm, which is **a linear regression with a least-squares penalty**. Given a training set $ D = \\left\\{ \\left(x^{(i)}, y^{(i)}\\right), x^{(i)} \\in \\mathcal{X}, y^{(i)} \\in \\mathcal{Y}, i \\in \\{1, \\dots, n \\}  \\right\\}$, recall (from lectures 1 and 2) OLS aims at minimizing the following cost function $J$:\n",
    "$$J(\\theta) = \\dfrac{1}{2} \\sum_{i = 1}^{n} \\left( h\\left(x^{(i)}\\right) - y^{(i)} \\right)^2$$\n",
    "where \n",
    "$$h(x) = \\sum_{j = 0}^{d} \\theta_j x_j = \\theta^T x.$$\n",
    "\n",
    "For the sake of simplicity, we will be working on a small training set (the one we used in lectures 1 and 2):\n",
    "\n",
    "| living area (m$^2$) | price (1000's BGN)|\n",
    "|--------------------:|------------------:|\n",
    "|                 50  |         30        |\n",
    "|                 76  |         48        |\n",
    "|                 26  |         12        |\n",
    "|                102  |         90        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Defining the training set\n",
    "**Exercise 1**: Define variables `X` and `Y` that will contain the features $\\mathcal{X}$ and labels $\\mathcal{Y}$ of the training set.\n",
    "\n",
    "**Hint**: Do not forget the intercept!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = [[1., 50.], [1., 76.], [1., 26.], [1., 102.]]\n",
    "Y = [30., 48., 12., 90.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this simple example, the dimensionality is $d = 1$ (which means 2 features: don't forget the intercept!) and the number of samples is $n = 4$.\n",
    "\n",
    "**Remark**: `1.` is written instead of `1` in order to avoid *integers operations*. For example, in some languages (including Python 2), the result of `1/2` is `0` and not `0.5`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, writing `1./2` forces a *float operation* and gives `0.5` as a result, which is what we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1./2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Prediction function\n",
    "**Exercise**: Define a function `predict` that takes as parameter *the feature vector* $x$ and *the model* $\\theta$ and returns the predicted label:\n",
    "$$ \\hat{y} = h(x) = \\theta^T x = \\sum_{j = 0}^d \\theta_j x_j$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict(x, theta):\n",
    "    y_hat = x[0] * theta[0] + x[1] * theta[1] # compute the dot product between 'theta' and 'x'\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Defining the cost function\n",
    "### Cost function on a single sample\n",
    "**Exercise**: Define a function `cost_function` that takes as parameter *the predicted label* $y$ and *the actual label* $\\hat{y}$ of a single sample and returns the value of the cost function for this pair. Recall from lectures 1 and 2 that it is given by:\n",
    "$$ \\ell \\left( y, \\hat{y} \\right) = \\dfrac{1}{2}\\left( y - \\hat{y} \\right)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cost_function(y, y_hat):\n",
    "    loss = (y - y_hat) ** 2 / 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cost function on the whole training set\n",
    "We are now able to compute the cost function for a single sample. We can easily compute the cost function for the whole training set by summing the cost function values for all the samples in the training set. Recall that the total cost function is given by:\n",
    "$$J(\\theta) = \\dfrac{1}{2} \\sum_{i = 1}^{n} \\left( h\\left(x^{(i)}\\right) - y^{(i)} \\right)^2$$\n",
    "where, for all $i \\in \\{ 1, \\dots, n \\}$\n",
    "$$h\\left(x^{(i)}\\right) = \\sum_{j = 0}^{d} \\theta_j x^{(i)}_j = \\theta^T x^{(i)}$$\n",
    "is the prediction of $x$ given the model $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cost_function_total(X, Y, theta):\n",
    "    cost = 0 # initialize the cost with 0\n",
    "    n = len(Y)\n",
    "    for i in range(n): # iterate over the training set (n = 4 in our case)\n",
    "        x = X[i] # get the ith feature vector\n",
    "        y = Y[i] # get the ith label\n",
    "        y_hat = predict(x, theta) # predict the ith label\n",
    "        cost += cost_function(y, y_hat) # add the cost of the current sample to the total cost\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's now test the code written above and check the total cost function we would have when $\\theta = [0, 0]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5724.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_0 = [0, 0]\n",
    "cost_function_total(X, Y, theta_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this error is big, which is expectable because having $\\theta = [0, 0]$ means always predicting $\\hat{y} = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Defining the gradient of the cost function\n",
    "### Gradient on a single sample\n",
    "**Exercise**: Define a function `gradient` that implements the gradient of the cost function for a given sample $(x, y)$. Recall from the lectures 1 and 2 that the gradient is given by:\n",
    "$$\\nabla J(\\theta) = \\left[ \\dfrac{\\partial}{\\partial \\theta_1} J(\\theta), \\dots, \\dfrac{\\partial}{\\partial \\theta_d} J(\\theta) \\right]^T$$\n",
    "where, for all $j \\in \\{0, \\dots, d \\}$:\n",
    "$$ \\dfrac{\\partial}{\\partial \\theta_j} J(\\theta) = \\left( h\\left(x\\right) - y \\right) x_j. $$\n",
    "**Hint**: Recall that $d = 1$, hence the gradient is of size $2$ (one value for $j = 0$, and another one for $j = 1$). Its two values are given by:\n",
    "$$ \\dfrac{\\partial}{\\partial \\theta_0} J(\\theta) = \\left( h\\left(x\\right) - y \\right) x_0 \\quad \\text{and} \\quad \n",
    "\\dfrac{\\partial}{\\partial \\theta_1} J(\\theta) = \\left( h\\left(x\\right) - y \\right) x_1. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gradient(x, y, theta):\n",
    "    grad = [0, 0]\n",
    "    grad[0] = (predict(x, theta) - y) * x[0] # first value of the gradient \n",
    "    grad[1] = (predict(x, theta) - y) * x[1] # second value of the gradient\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's try the `gradient` function on a simple example ($\\theta = [0, 0]$ on the first sample of the training set, *i.e.* $\\left(x^{(0)}, y^{(0)}\\right)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-30.0, -1500.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(X[0], Y[0], theta_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Gradient on the whole training set\n",
    "Now we are able to compute the gradient of the cost function on a single sample, we can easily compute `gradient_total`, the gradient of the cost function on the whole training set by summing the gradients for all the samples in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gradient_total(X, Y, theta):\n",
    "    grad_total = [0, 0] # initialize the gradient with zeros\n",
    "    n = len(Y)\n",
    "    for i in range(n): # iterate over the training set\n",
    "        x = X[i] # get the ith feature vector\n",
    "        y = Y[i] # get the ith label\n",
    "        grad = gradient(x, y, theta) # predict the ith label given 'theta'\n",
    "        grad_total[0] += grad[0] # add the gradient corresponding to theta[0]\n",
    "        grad_total[1] += grad[1] # add the gradient corresponding to theta[1]\n",
    "    return grad_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's now test the code written above and check the total gradient we would have when $\\theta = [0, 0]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-180.0, -14640.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_total(X, Y, theta_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Question**: What is the sign of the gradient values? What would it mean if we had such a gradient when applying a gradient descent?\n",
    "\n",
    "**Hint**: Recall the gradient descent update:\n",
    "$$\\theta_j := \\theta_j - \\alpha \\dfrac{\\partial}{\\partial \\theta_j} J(\\theta) \\quad \\text{for all } j \\in \\{0, \\dots, d \\}$$\n",
    "\n",
    "**Answer**: Both values are negative, which means this gradient step would increase the value of $\\theta$ due to fact we **substract** the gradient. This makes sense, because:\n",
    "- we start with $\\theta = [0, 0]$,\n",
    "- we expect $\\theta_0 > 0$ and $\\theta_1 > 0$ because otherwise we could predict a negative price.\n",
    "\n",
    "## Applying a gradient descent\n",
    "### Gradient descent step implementation\n",
    "We now have all the building blocs needed for the gradient descent algorithm, that is:\n",
    "- The loss function\n",
    "- The gradient\n",
    "Indeed, the iterative update scheme of this algorithm is given by the following formula:\n",
    "$$\\theta_j := \\theta_j - \\alpha \\dfrac{\\partial}{\\partial \\theta_j} J(\\theta)$$\n",
    "for all $j \\in \\{0, \\dots, d \\}$. Recall that $\\alpha$ is a parameter called the *learning rate* (or *step size*).\n",
    "\n",
    "**Exercise**: Define a function called `gradient_descent_step` that performs an update on theta by applying the formula above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_step(X, Y, theta, alpha):\n",
    "    theta_updated = [0, 0]\n",
    "    grad = gradient_total(X, Y, theta)\n",
    "    theta_updated[0] = theta[0] - alpha * grad[0]\n",
    "    theta_updated[1] = theta[1] - alpha * grad[1]\n",
    "    return theta_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Try to run a few iterations manually. Play with the value of $\\alpha$ to see how it impacts the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0011927999999999973, 0.0938243999999997]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.0001\n",
    "theta_1 = gradient_descent_step(X, Y, theta_0, alpha)\n",
    "theta_2 = gradient_descent_step(X, Y, theta_1, alpha)\n",
    "theta_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Iterating gradient descent steps\n",
    "The `gradient_descent_step` implements a single gradient step of the gradient descent algorithm. Implement a function called `gradient_descent` that starts from a given $\\theta$ (exaple $\\theta = [0, 0]$) and applies 100 gradient descent iterations. Display the total cost function $J(\\theta)$ at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, alpha):\n",
    "    theta = [0, 0] # initializing theta with zeros (it can be initialized in another manner)\n",
    "    n_iteration_max = 100\n",
    "    for i_iteration in range(n_iteration_max):\n",
    "        loss = cost_function_total(X, Y, theta)\n",
    "        print(\"Iteration {:>2}. Current loss = {}\".format(i_iteration, loss))\n",
    "        theta = gradient_descent_step(X, Y, theta, alpha)\n",
    "    loss = cost_function_total(X, Y, theta)\n",
    "    print(\"Optimization complete. Final loss = {}\".format(loss))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Play with the code you've just run. Try different values of $\\alpha$ and see the impact it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0. Current loss = 5724.0\n",
      "Iteration  1. Current loss = 5037.312744\n",
      "Iteration  2. Current loss = 4435.7926733\n",
      "Iteration  3. Current loss = 3908.87660327\n",
      "Iteration  4. Current loss = 3447.31148851\n",
      "Iteration  5. Current loss = 3042.99192789\n",
      "Iteration  6. Current loss = 2688.81782352\n",
      "Iteration  7. Current loss = 2378.56969424\n",
      "Iteration  8. Current loss = 2106.79945376\n",
      "Iteration  9. Current loss = 1868.73473546\n",
      "Iteration 10. Current loss = 1660.19508368\n",
      "Iteration 11. Current loss = 1477.51853971\n",
      "Iteration 12. Current loss = 1317.49733324\n",
      "Iteration 13. Current loss = 1177.32154991\n",
      "Iteration 14. Current loss = 1054.52978568\n",
      "Iteration 15. Current loss = 946.965921541\n",
      "Iteration 16. Current loss = 852.741259375\n",
      "Iteration 17. Current loss = 770.201354036\n",
      "Iteration 18. Current loss = 697.896959252\n",
      "Iteration 19. Current loss = 634.558577041\n",
      "Iteration 20. Current loss = 579.074163751\n",
      "Iteration 21. Current loss = 530.469601184\n",
      "Iteration 22. Current loss = 487.891589865\n",
      "Iteration 23. Current loss = 450.59266404\n",
      "Iteration 24. Current loss = 417.918065244\n",
      "Iteration 25. Current loss = 389.294243928\n",
      "Iteration 26. Current loss = 364.218787212\n",
      "Iteration 27. Current loss = 342.251595891\n",
      "Iteration 28. Current loss = 323.007155739\n",
      "Iteration 29. Current loss = 306.147767403\n",
      "Iteration 30. Current loss = 291.377615979\n",
      "Iteration 31. Current loss = 278.437576137\n",
      "Iteration 32. Current loss = 267.10066155\n",
      "Iteration 33. Current loss = 257.168038739\n",
      "Iteration 34. Current loss = 248.465535303\n",
      "Iteration 35. Current loss = 240.840581238\n",
      "Iteration 36. Current loss = 234.159529618\n",
      "Iteration 37. Current loss = 228.305309583\n",
      "Iteration 38. Current loss = 223.175370436\n",
      "Iteration 39. Current loss = 218.679880719\n",
      "Iteration 40. Current loss = 214.740150664\n",
      "Iteration 41. Current loss = 211.287250302\n",
      "Iteration 42. Current loss = 208.260798966\n",
      "Iteration 43. Current loss = 205.607904929\n",
      "Iteration 44. Current loss = 203.282236566\n",
      "Iteration 45. Current loss = 201.243208706\n",
      "Iteration 46. Current loss = 199.455269908\n",
      "Iteration 47. Current loss = 197.887278137\n",
      "Iteration 48. Current loss = 196.511953863\n",
      "Iteration 49. Current loss = 195.305401008\n",
      "Iteration 50. Current loss = 194.246687295\n",
      "Iteration 51. Current loss = 193.31747665\n",
      "Iteration 52. Current loss = 192.501707203\n",
      "Iteration 53. Current loss = 191.785309219\n",
      "Iteration 54. Current loss = 191.155958013\n",
      "Iteration 55. Current loss = 190.602857518\n",
      "Iteration 56. Current loss = 190.11655069\n",
      "Iteration 57. Current loss = 189.688753431\n",
      "Iteration 58. Current loss = 189.312209109\n",
      "Iteration 59. Current loss = 188.980561123\n",
      "Iteration 60. Current loss = 188.688241277\n",
      "Iteration 61. Current loss = 188.430371987\n",
      "Iteration 62. Current loss = 188.202680633\n",
      "Iteration 63. Current loss = 188.001424523\n",
      "Iteration 64. Current loss = 187.823325164\n",
      "Iteration 65. Current loss = 187.665510694\n",
      "Iteration 66. Current loss = 187.525465442\n",
      "Iteration 67. Current loss = 187.400985754\n",
      "Iteration 68. Current loss = 187.290141292\n",
      "Iteration 69. Current loss = 187.191241135\n",
      "Iteration 70. Current loss = 187.102804087\n",
      "Iteration 71. Current loss = 187.02353266\n",
      "Iteration 72. Current loss = 186.952290295\n",
      "Iteration 73. Current loss = 186.888081396\n",
      "Iteration 74. Current loss = 186.830033851\n",
      "Iteration 75. Current loss = 186.777383715\n",
      "Iteration 76. Current loss = 186.729461795\n",
      "Iteration 77. Current loss = 186.685681895\n",
      "Iteration 78. Current loss = 186.645530527\n",
      "Iteration 79. Current loss = 186.608557887\n",
      "Iteration 80. Current loss = 186.574369962\n",
      "Iteration 81. Current loss = 186.542621608\n",
      "Iteration 82. Current loss = 186.513010487\n",
      "Iteration 83. Current loss = 186.485271761\n",
      "Iteration 84. Current loss = 186.459173439\n",
      "Iteration 85. Current loss = 186.434512303\n",
      "Iteration 86. Current loss = 186.411110342\n",
      "Iteration 87. Current loss = 186.388811622\n",
      "Iteration 88. Current loss = 186.367479547\n",
      "Iteration 89. Current loss = 186.346994468\n",
      "Iteration 90. Current loss = 186.327251571\n",
      "Iteration 91. Current loss = 186.308159044\n",
      "Iteration 92. Current loss = 186.289636463\n",
      "Iteration 93. Current loss = 186.271613377\n",
      "Iteration 94. Current loss = 186.254028075\n",
      "Iteration 95. Current loss = 186.236826499\n",
      "Iteration 96. Current loss = 186.219961295\n",
      "Iteration 97. Current loss = 186.203390982\n",
      "Iteration 98. Current loss = 186.187079226\n",
      "Iteration 99. Current loss = 186.170994198\n",
      "Optimization complete. Final loss = 186.155108016\n"
     ]
    }
   ],
   "source": [
    "theta_trained_gd = gradient_descent(X, Y, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.11087633725023004, 0.7567940140789401]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_trained_gd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Question**: Looks at the evolution of the cost function over time. What comment can you make?\n",
    "\n",
    "**Answer**: The loss function constantly drops over time with this initial value of $\\theta$ and this $\\alpha$. It ends up reaching a plateau at around 186. It seems like the algorithm has converged to the optimal value of the cost function.\n",
    "\n",
    "**Question**: What does the value `theta_trained` represent?\n",
    "\n",
    "**Answer**: Recall that the model $\\theta$ has to values, $\\theta_0$ and $\\theta_1$. Hence, with the model `theta_trained` we've learnt, price prediction would be:\n",
    "$$ \\text{price} = \\theta_0 + \\theta_1 \\times \\text{area}.$$\n",
    "\n",
    "## Batch gradient descent vs. stochastic gradient descent\n",
    "As we have seen during the lecture 1, the gradient descent methods are often split into 2 different subfamilies:\n",
    "- **Batch methods** update $\\theta$ after having computed the gradient on the whole training set\n",
    "- **Stochastic methods** update $\\theta$ after having computed the gradient on a single sample\n",
    "The gradient descent we have implemented above (`gradient_descent_step` and `gradient_descent`) corresponds to the batch version because it sums the gradient of all the samples in the training set. \n",
    "\n",
    "**Exercise**: Try to implement the stochastic version of the gradient descent algorithm.\n",
    "\n",
    "** Solution**: We first need to define a function that implements a stochastic gradient step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent_step(x, y, theta, alpha):\n",
    "    theta_updated = [0, 0]\n",
    "    grad = gradient(x, y, theta)\n",
    "    theta_updated[0] = theta[0] - alpha * grad[0]\n",
    "    theta_updated[1] = theta[1] - alpha * grad[1]\n",
    "    return theta_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define the stochastic gradient descent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, Y, alpha):\n",
    "    theta = [0, 0] # initializing theta with zeros (it can be initialized in another manner)\n",
    "    n_iteration_max = 100\n",
    "    n_samples = len(Y)\n",
    "    for i_iteration in range(n_iteration_max):\n",
    "        i_sample = i_iteration % n_samples\n",
    "        loss = cost_function_total(X, Y, theta)\n",
    "        print(\"Iteration {:>2}. Current loss = {}\".format(i_iteration, loss))\n",
    "        theta = stochastic_gradient_descent_step(X[i_sample], Y[i_sample], theta, alpha) # run the gradient update on a single sample\n",
    "    loss = cost_function_total(X, Y, theta)\n",
    "    print(\"Optimization complete. Final loss = {}\".format(loss))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now apply the algorithm with the same parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0. Current loss = 5724.0\n",
      "Iteration  1. Current loss = 3745.329318\n",
      "Iteration  2. Current loss = 1229.58850556\n",
      "Iteration  3. Current loss = 1215.4002507\n",
      "Iteration  4. Current loss = 389.24889887\n",
      "Iteration  5. Current loss = 233.848727077\n",
      "Iteration  6. Current loss = 205.389900038\n",
      "Iteration  7. Current loss = 222.353897307\n",
      "Iteration  8. Current loss = 360.244624812\n",
      "Iteration  9. Current loss = 223.650823333\n",
      "Iteration 10. Current loss = 208.315174237\n",
      "Iteration 11. Current loss = 226.1195284\n",
      "Iteration 12. Current loss = 360.544262454\n",
      "Iteration 13. Current loss = 223.744191112\n",
      "Iteration 14. Current loss = 208.259993315\n",
      "Iteration 15. Current loss = 226.051269403\n",
      "Iteration 16. Current loss = 360.506758085\n",
      "Iteration 17. Current loss = 223.72195803\n",
      "Iteration 18. Current loss = 208.241787391\n",
      "Iteration 19. Current loss = 226.030015382\n",
      "Iteration 20. Current loss = 360.473292026\n",
      "Iteration 21. Current loss = 223.701111748\n",
      "Iteration 22. Current loss = 208.22314266\n",
      "Iteration 23. Current loss = 226.008202949\n",
      "Iteration 24. Current loss = 360.439782616\n",
      "Iteration 25. Current loss = 223.680252259\n",
      "Iteration 26. Current loss = 208.204506343\n",
      "Iteration 27. Current loss = 225.986400695\n",
      "Iteration 28. Current loss = 360.406278661\n",
      "Iteration 29. Current loss = 223.659396303\n",
      "Iteration 30. Current loss = 208.185873091\n",
      "Iteration 31. Current loss = 225.964601821\n",
      "Iteration 32. Current loss = 360.372779578\n",
      "Iteration 33. Current loss = 223.638543679\n",
      "Iteration 34. Current loss = 208.167242968\n",
      "Iteration 35. Current loss = 225.942806408\n",
      "Iteration 36. Current loss = 360.339285373\n",
      "Iteration 37. Current loss = 223.617694391\n",
      "Iteration 38. Current loss = 208.148615972\n",
      "Iteration 39. Current loss = 225.921014454\n",
      "Iteration 40. Current loss = 360.305796044\n",
      "Iteration 41. Current loss = 223.596848436\n",
      "Iteration 42. Current loss = 208.129992103\n",
      "Iteration 43. Current loss = 225.899225958\n",
      "Iteration 44. Current loss = 360.272311592\n",
      "Iteration 45. Current loss = 223.576005815\n",
      "Iteration 46. Current loss = 208.111371359\n",
      "Iteration 47. Current loss = 225.87744092\n",
      "Iteration 48. Current loss = 360.238832014\n",
      "Iteration 49. Current loss = 223.555166527\n",
      "Iteration 50. Current loss = 208.092753742\n",
      "Iteration 51. Current loss = 225.85565934\n",
      "Iteration 52. Current loss = 360.205357312\n",
      "Iteration 53. Current loss = 223.534330572\n",
      "Iteration 54. Current loss = 208.07413925\n",
      "Iteration 55. Current loss = 225.833881217\n",
      "Iteration 56. Current loss = 360.171887483\n",
      "Iteration 57. Current loss = 223.513497948\n",
      "Iteration 58. Current loss = 208.055527883\n",
      "Iteration 59. Current loss = 225.81210655\n",
      "Iteration 60. Current loss = 360.138422527\n",
      "Iteration 61. Current loss = 223.492668656\n",
      "Iteration 62. Current loss = 208.036919639\n",
      "Iteration 63. Current loss = 225.790335338\n",
      "Iteration 64. Current loss = 360.104962444\n",
      "Iteration 65. Current loss = 223.471842695\n",
      "Iteration 66. Current loss = 208.01831452\n",
      "Iteration 67. Current loss = 225.768567583\n",
      "Iteration 68. Current loss = 360.071507233\n",
      "Iteration 69. Current loss = 223.451020064\n",
      "Iteration 70. Current loss = 207.999712524\n",
      "Iteration 71. Current loss = 225.746803281\n",
      "Iteration 72. Current loss = 360.038056892\n",
      "Iteration 73. Current loss = 223.430200763\n",
      "Iteration 74. Current loss = 207.98111365\n",
      "Iteration 75. Current loss = 225.725042434\n",
      "Iteration 76. Current loss = 360.004611422\n",
      "Iteration 77. Current loss = 223.409384791\n",
      "Iteration 78. Current loss = 207.962517899\n",
      "Iteration 79. Current loss = 225.703285041\n",
      "Iteration 80. Current loss = 359.971170821\n",
      "Iteration 81. Current loss = 223.388572148\n",
      "Iteration 82. Current loss = 207.943925269\n",
      "Iteration 83. Current loss = 225.681531101\n",
      "Iteration 84. Current loss = 359.937735088\n",
      "Iteration 85. Current loss = 223.367762834\n",
      "Iteration 86. Current loss = 207.925335761\n",
      "Iteration 87. Current loss = 225.659780613\n",
      "Iteration 88. Current loss = 359.904304224\n",
      "Iteration 89. Current loss = 223.346956847\n",
      "Iteration 90. Current loss = 207.906749373\n",
      "Iteration 91. Current loss = 225.638033577\n",
      "Iteration 92. Current loss = 359.870878227\n",
      "Iteration 93. Current loss = 223.326154187\n",
      "Iteration 94. Current loss = 207.888166106\n",
      "Iteration 95. Current loss = 225.616289993\n",
      "Iteration 96. Current loss = 359.837457097\n",
      "Iteration 97. Current loss = 223.305354854\n",
      "Iteration 98. Current loss = 207.869585958\n",
      "Iteration 99. Current loss = 225.594549859\n",
      "Optimization complete. Final loss = 359.804040832\n"
     ]
    }
   ],
   "source": [
    "theta_trained_sgd = stochastic_gradient_descent(X, Y, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Compare the results obtained when solving the OLS problem with stochastic gradient descent and batch gradient descent. Are the results the same? If no, how could it be the case?\n",
    "\n",
    "**Hint**: Plot the loss function.\n",
    "\n",
    "**Answer**: The results are not the same, the loss function value differs a lot. To understand what happens, let's look at what the function looks like. It is a function of 2 variables ($\\theta_0$ and $\\theta_1$), so we can use either a *3D plot* or a *contour plot* for visualize it. The following code shows the *contour plot*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dtheta = 0.001\n",
    "theta0_vector = np.arange(-1,1, dtheta)\n",
    "theta1_vector = np.arange(-1,1, dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n0 = len(theta0_vector)\n",
    "n1 = len(theta1_vector)\n",
    "loss = np.zeros([n0, n1])\n",
    "for i0 in range(n0):\n",
    "    for i1 in range(n1):\n",
    "        loss[i0, i1] = cost_function_total(X, Y, [theta0_vector[i0], theta1_vector[i1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "cs = plt.contourf(theta0_vector, theta1_vector, loss)\n",
    "cbar = fig.colorbar(cs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at what the function from \"further away\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtheta = 1.\n",
    "theta0_vector = np.arange(-100,100, dtheta)\n",
    "theta1_vector = np.arange(-100,100, dtheta)\n",
    "n0 = len(theta0_vector)\n",
    "n1 = len(theta1_vector)\n",
    "loss = np.zeros([n0, n1])\n",
    "for i0 in range(n0):\n",
    "    for i1 in range(n1):\n",
    "        loss[i0, i1] = cost_function_total(X, Y, [theta0_vector[i0], theta1_vector[i1]])\n",
    "fig = plt.figure()\n",
    "cs = plt.contourf(theta0_vector, theta1_vector, loss)\n",
    "cbar = fig.colorbar(cs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the function behaves very differently on the two axis:\n",
    "- It varies very fast on the horizontal axis\n",
    "- It varies very slowly on the vertical axis\n",
    "\n",
    "**Question**: What could this be due to? How could we solve this issue?\n",
    "\n",
    "**Answer**: This is due to the fact that the two features (the size and the intercept) are on very different scales: the intercept is constantly equal to 1, while the size of the house varies on a much wider range (up to 102). In our algorithm, we make no difference between $\\theta_0$ and $\\theta_1$: the same step-size is \n",
    "A way to address this issue is to normalize the features. There are several ways to do it:\n",
    "1. The first way consists in, for each feature, dividing all the feature values by its maximal value. In the case of the house size, it would consist in dividing all the house sizes by 102, so that the biggest house would have a size of 1.\n",
    "2. Another way consists in computing the $z$-score of the feature:\n",
    "$$ z = \\dfrac{x - x_{\\min}}{x_{\\max} - x_{\\min}} $$\n",
    "so that the feature respectively has -1 and 1 as minimum and maximum value. Note that this does not apply to the intercept $x_0$, because it is constantly equal to $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homeworks**: \n",
    "1. Implement the feature normalization of your choice. Run the OLS algorithm on it, and compare the result with the non-normalized regression. \n",
    "2. Add an *outlier* to the training set (for example, a house with a normal size but a very small or very big price), and run the OLS algorithm on it. What impact does the outlier have on the quality of the regression? How to correct this issue?\n",
    "\n",
    "In the next session, we will talk about regularization and how to define a more complex model when the data is not linearly separable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
